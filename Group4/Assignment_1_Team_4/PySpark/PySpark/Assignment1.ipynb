{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error for SVMWithSGD - L1 = 0.0367496937526\n",
      "Training Error for SVMWithSGD - L2 = 0.0367496937526\n"
     ]
    }
   ],
   "source": [
    "#SVMWithSGD\n",
    "\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    return LabeledPoint(values[11], values[0:10])\n",
    "\n",
    "data = sc.textFile(\"winequality-white.csv\")\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Build the model with L1 penalty \n",
    "model1 = SVMWithSGD.train(parsedData, regType='l1', step=0.0001)\n",
    "\n",
    "# Build the model with L2 penalty\n",
    "model2 = SVMWithSGD.train(parsedData, regType='l2')\n",
    "\n",
    "# Evaluating the model with L1 on training data\n",
    "labelsAndPreds1 = parsedData.map(lambda p: (p.label, model1.predict(p.features)))\n",
    "\n",
    "# Evaluating the model with L2 on training data\n",
    "labelsAndPreds2 = parsedData.map(lambda p: (p.label, model2.predict(p.features)))\n",
    "\n",
    "#Calculating training error for model with L1\n",
    "trainErr1 = labelsAndPreds1.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Training Error for SVMWithSGD - L1 = \" + str(trainErr1))\n",
    "\n",
    "#Calculating training error for model with L2\n",
    "trainErr2 = labelsAndPreds2.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Training Error for SVMWithSGD - L2 = \" + str(trainErr2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error for LogisticRegressionWithLBFGS - L1 = 0.0367496937526\n",
      "Training Error for LogisticRegressionWithLBFGS - L2 = 0.0367496937526\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegressionWithLBFGS\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "from pyspark.mllib.feature import Normalizer\n",
    "\n",
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    return LabeledPoint(values[11], values[0:10])\n",
    "\n",
    "data = sc.textFile(\"winequality-white.csv\")\n",
    "\n",
    "#nor = Normalizer(1)\n",
    "#norData = nor.transform(data).collect()\n",
    "\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Build the model with L1 penalty \n",
    "model1 = LogisticRegressionWithLBFGS.train(parsedData, regType='l1')\n",
    "\n",
    "# Build the model with L2 penalty\n",
    "model2 = LogisticRegressionWithLBFGS.train(parsedData, regType='l2')\n",
    "\n",
    "# Evaluating the model with L1 on training data\n",
    "labelsAndPreds1 = parsedData.map(lambda p: (p.label, model1.predict(p.features)))\n",
    "\n",
    "# Evaluating the model with L2 on training data\n",
    "labelsAndPreds2 = parsedData.map(lambda p: (p.label, model2.predict(p.features)))\n",
    "\n",
    "#Calculating training error for model with L1\n",
    "trainErr1 = labelsAndPreds1.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Training Error for LogisticRegressionWithLBFGS - L1 = \" + str(trainErr1))\n",
    "\n",
    "#Calculating training error for model with L2\n",
    "trainErr2 = labelsAndPreds2.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Training Error for LogisticRegressionWithLBFGS - L2 = \" + str(trainErr2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error for LogisticRegressionWithSGD - L1 = 0.0367496937526\n",
      "Training Error for LogisticRegressionWithSGD - L2 = 0.0467537770519\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegressionWithSGD\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "from pyspark.mllib.feature import Normalizer\n",
    "\n",
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "    return LabeledPoint(values[11], values[0:10])\n",
    "\n",
    "data = sc.textFile(\"winequality-white.csv\")\n",
    "\n",
    "#nor = Normalizer(1)\n",
    "#norData = nor.transform(data).collect()\n",
    "\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Build the model with L1 penalty \n",
    "model1 = LogisticRegressionWithSGD.train(parsedData, regType='l1', iterations=100, step=0.0001, regParam = 0.00001)\n",
    "\n",
    "# Build the model with L2 penalty\n",
    "model2 = LogisticRegressionWithSGD.train(parsedData, regType='l2')\n",
    "\n",
    "# Evaluating the model with L1 on training data\n",
    "labelsAndPreds1 = parsedData.map(lambda p: (p.label, model1.predict(p.features)))\n",
    "\n",
    "# Evaluating the model with L2 on training data\n",
    "labelsAndPreds2 = parsedData.map(lambda p: (p.label, model2.predict(p.features)))\n",
    "\n",
    "#Calculating training error for model with L1\n",
    "trainErr1 = labelsAndPreds1.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Training Error for LogisticRegressionWithSGD - L1 = \" + str(trainErr1))\n",
    "\n",
    "#Calculating training error for model with L2\n",
    "trainErr2 = labelsAndPreds2.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Training Error for LogisticRegressionWithSGD - L2 = \" + str(trainErr2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for LinearRegressionWithSGD = 4.2568240886\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD \n",
    "from numpy import array\n",
    "\n",
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.replace(',', ' ').split(' ')]\n",
    "    return LabeledPoint(values[0], values[1:])\n",
    "\n",
    "data = sc.textFile(\"winequality-white.csv\")\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Build the model\n",
    "model = LinearRegressionWithSGD.train(parsedData,100,0.0001)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "valuesAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "MSE = valuesAndPreds.map(lambda (v, p): (v - p)**2).reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "print(\"Mean Squared Error for LinearRegressionWithSGD = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for RidgeRegressionWithSGD = 4.25682589184\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, RidgeRegressionWithSGD \n",
    "from numpy import array\n",
    "\n",
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.replace(',', ' ').split(' ')]\n",
    "    return LabeledPoint(values[0], values[1:])\n",
    "\n",
    "data = sc.textFile(\"winequality-white.csv\")\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Build the model\n",
    "model = RidgeRegressionWithSGD.train(parsedData,100,0.0001)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "valuesAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "MSE = valuesAndPreds.map(lambda (v, p): (v - p)**2).reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "print(\"Mean Squared Error for RidgeRegressionWithSGD = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for LassoWithSGD = 4.25710987027\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LassoWithSGD \n",
    "from numpy import array\n",
    "\n",
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.replace(',', ' ').split(' ')]\n",
    "    return LabeledPoint(values[0], values[1:])\n",
    "\n",
    "data = sc.textFile(\"winequality-white.csv\")\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Build the model\n",
    "model = LassoWithSGD.train(parsedData,100,step=0.0001)\n",
    "\n",
    "# Evaluate the model on training data\n",
    "valuesAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "MSE = valuesAndPreds.map(lambda (v, p): (v - p)**2).reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "print(\"Mean Squared Error for LassoWithSGD = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x10d6c18d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
